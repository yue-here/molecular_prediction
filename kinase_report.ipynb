{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing enzyme inhibitors\n",
    "Contents:<br>\n",
    "[Exploratory data analysis](#exploratory-data-analysis)<br>\n",
    "[Data processing](#data-processing)<br>\n",
    "[Traditional ML baseline](#traditional-ml-baseline)<br>\n",
    "[SMILES transformer model](#smiles-transformer-model)<br>\n",
    "[Graph neural network model](#graph-neural-network-model)<br>\n",
    "[Discussion](#discussion)<br>\n",
    "***\n",
    "## Overview\n",
    "This notebook discusses a project on, broadly, predicting the enzyme inhibition ability of molecules using deep learning, starting from SMILES representations of the molecules. All identifying parts have redacted for privacy reasons and the code won't run as a result.\n",
    "\n",
    "I implemented three model types for comparison: a traditional machine learning  using gradient boosting as baseline model, a transformer operating on SMILES strings, and a graph neural network operating on molecular graphs. I discuss the design, testing and evaluation of each model, and present some simple examples of deployment as a web service.\n",
    "\n",
    "***\n",
    "Notes:<br>\n",
    "* Project files are in the src subfolder; specific model files are in the src/gnn and src/transformer subfolders. Mentioned files are hyperlinked.\n",
    "* ML experiment tracking using mlflow was used throughout, and can be accessed by running a local mlflow server. The tracking files are stored in the \"mlruns\" folder.\n",
    "* Model weights were also stored as mlflow artifacts; these are not included due to size constraints (available on request).\n",
    "* Mlflow hyperlinks to relevant experiments are provided with the assumption the mlflow server is running locally on http://127.0.0.1:5000\n",
    "* The `uv` package manager was used and the virtual environment can be installed using `uv sync` from the project root directory.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "### Data overview\n",
    "We make the relevant imports and load the data. It contains:\n",
    "* SMILES representations of the molecules\n",
    "* Categorical features for measurement types (2) and enzyme names (4)\n",
    "* Values of pKi (and pIC50, a related value) measurements as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('./DATA.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the size and shape of the provided dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Size of dataframe: {df.shape}')\n",
    "print(f'measurement_type: {df.measurement_type.value_counts()}')\n",
    "print(f'Enzyme_name: {df.Enzyme_name.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify data classes\n",
    "\n",
    "While this is a regression problem, we can identify $n_{measurement-type} \\times n_{Enzyme-name} = 8$ distinct subclassew within the data.\n",
    "\n",
    "We can consider each of these classes as coming from a different underlying distribution arising from a given combination of measurement type and kinase.\n",
    "\n",
    "We can cross-tabulate `measurement_type` against `Enzymes_name` to see how well these classes are represented.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like each class does have a distinct distribution. A good ML model should be able learn these associations if provided with appropriate conditioning to separate classes.\n",
    "\n",
    "Consideration: if the different measurement classes were on different orders of magnitude, it would affect the gradients for backpropagation. Something like min-max scaling within classes might be useful there. Checking the range of the measurement values shows that they all lie within a small range of 6 to 12.24, so scaling is probably unneccesary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore molecule distribution\n",
    "\n",
    "We can look at how many times each molecule is represented in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_counts = df['SMILES'].value_counts()\n",
    "print(f'number of unique SMILES: {len(smiles_counts)}')\n",
    "print(smiles_counts)\n",
    "print(smiles_counts.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rdkit descriptors\n",
    "\n",
    "Let's calculate all the rdkit descriptors for the dataset - we use as these inputs for a traditional ML model to provide a comparison for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "\n",
    "def featurize_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        calc = MolecularDescriptorCalculator([desc[0] for desc in Descriptors.descList])\n",
    "        features = dict(zip(calc.GetDescriptorNames(), calc.CalcDescriptors(mol)))\n",
    "    else:\n",
    "        features = {desc[0]: None for desc in Descriptors.descList}\n",
    "    return features\n",
    "\n",
    "# Apply the featurization\n",
    "features_df = df['SMILES'].apply(featurize_smiles)\n",
    "features_df = pd.json_normalize(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this file for convenience as it takes a few minutes to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('rdkit_features.csv', index=False)\n",
    "# features_df = pd.read_csv('rdkit_features.csv') # for loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to easily inspect many more chemical features - e.g. the molecular weight distribution of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_df.MolWt.hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA summary\n",
    "\n",
    "* The data are imbalanced with respect to both measurement type and enzyme type. Will need to carefully design dev/test sets so that all classes are well represented.\n",
    "* We have both pKi and pIC50; the problem statement is to predict pKi. We want to design a model that utilizes all data over both measurement types and all classes so that it can generalise well.\n",
    "* For deep-learning models, regression outputs will need to be conditioned on measurement classes. This will also allow pIC50 measurements to be fully utilized for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Due to the structure of the dataset, a `create_stratified_splits` function (located in [utils.py](src/utils.py)) is used instead of a standard train-development-test split function. (Note - I've used 'validation' and 'development' interchangeably in some cases)\n",
    "\n",
    "This function addresses two issues with the dataset:\n",
    "1. The target measurement is pKi, so dev and test splits with only pKi measurements were used for evaluation\n",
    "2. The classes are very imbalanced, so the function specifies a fixed number of samples per class.\n",
    "The dev and test sets have been set at 60 samples per class in order maintain a balance between sufficiently large splits and adequate representation of the smallest class.\n",
    "\n",
    "For each model type presented, additional model-specific data processing is discussed in that section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional ML baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to train_baseline.py](src/train_baseline.py)\n",
    "\n",
    "A scikit-learn gradient boosting (GB) regressor was used as a traditional ML baseline comparison to the deep-learning models. The GB model was chosen as a generally effective and well-known technique for tabular data. The rdkit features calculated earlier in this notebook, plus one-hot encodings of the categorical features, were used as features.\n",
    "\n",
    "A single round of hyperparameter tuning was performed via optuna. This experiment is tracked in the mlflow experiment \"[sklearn GB Architecture Search 2](http://127.0.0.1:5000/#/experiments/656276792890615830?viewStateShareKey=5573798af4a32b741e536254987277f23c1668ffa1b1182466fda950e7ce8f3b)\".\n",
    "\n",
    "The following key parameters were tuned:\n",
    "* Number of estimators in the ensemble (`n_estimators`). Range: 20-200\n",
    "* Maximum depth of estimators (`max_depth`). Range: 3-30\n",
    "* Learning rate (`learning_rate`). Range: 0.01-0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning results for the gradient boosting model are shown in the parallel coordinates plot below. The plot suggests the ranges we set for tunable parameters are good as the optimal values lie within our chosen ranges.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"figures/gradient_boosting_optuna.png\" alt=\"Gradient Boosting Optuna\">\n",
    "    <br>\n",
    "    <em>Parallel coordinates plot showing hyperparameter search results. Each trace represents a single model and is colored by validation loss</em>\n",
    "</p>\n",
    "\n",
    "The minimum MSE obtained was ~0.32 on the dev set with parameters of max_depth = 8, n_estimators = 151, learning rate ~ 0.088. ([mlflow run](http://127.0.0.1:5000/#/experiments/656276792890615830/runs/8ac20f5615da41f0852b29fcab2784c1))\n",
    "\n",
    "### Model evaluation\n",
    "On the held-out test set, the per-class MSEs show that the model has much better performance on ENZ1 compared to the other classes ([mlflow run](http://127.0.0.1:5000/#/experiments/824897664922855667/runs/013a4bf8361942cc8a160dc2f3087561)). Worse performance on the underrepresented classes is expected, however overperformance on ENZ1 vs ENZ2 should be investigated further as these classes had a similar number of data samples.\n",
    "\n",
    "Kinase_name | pKi MSE\n",
    "--- | ---\n",
    "ENZ1 | 0.096965\n",
    "ENZ2 | 0.262585\n",
    "ENZ3 | 0.366490\n",
    "ENZ4 | 0.334674\n",
    "Overall | 0.265178\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example deployment\n",
    "[app_baseline.py](src/app_baseline.py)\n",
    "\n",
    "I demonstrate an interaction with simple test deployment of the model running as a web service on a local server below. The service is written in flask and runs a model pulled from the local mlflow server. The user sends the details of a molecule and the measurement conditions (SMILES string, measurement type (pKi or pIC50), and Kinase name (ENZ1, ENZ2, ENZ3, ENZ4)).\n",
    "\n",
    "The service featurizes the molecule, encodes the measurement conditions, runs the predictive model and returns a predicted value. (In this case, the real value is 7.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [7.456266114089111]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of the Flask app\n",
    "url = 'http://localhost:5001/predict'\n",
    "\n",
    "# Define the input data\n",
    "data = [\n",
    "    {\n",
    "        \"SMILES\": \"C#CCNCC1CCC(c2nnn3cnc4[nH]ccc4c23)CC1\",\n",
    "        \"measurement_type\": \"pIC50\",\n",
    "        \"enzyme_name\": \"ENZ2\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Send a POST request to the /predict endpoint\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Print the response from the server\n",
    "if response.status_code == 200:\n",
    "    print(\"Predictions:\", response.json())\n",
    "else:\n",
    "    print(\"Error:\", response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random chemical drawn from test set\n",
    "\n",
    "| SMILES | measurement_type | measurement_value | enzyme_name |\n",
    "|--------|------------------|-------------------|------------|\n",
    "| CN1CCN(C(=O)Cn2cc(NC(=O)c3cnn4cccnc34)c(-c3cc(Cl)ccc3OC(F)F)n2)C(C)(C)C1 | pKi | 9.25 | ENZ1 |\n",
    "| CN1CCN(C(=O)Cn2cc(NC(=O)c3cnn4cccnc34)c(-c3cc(Cl)ccc3OC(F)F)n2)C(C)(C)C1 | pKi | 8.89 | ENZ2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x12f00f990>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "Chem.MolFromSmiles(\"CN1CCN(C(=O)Cn2cc(NC(=O)c3cnn4cccnc34)c(-c3cc(Cl)ccc3OC(F)F)n2)C(C)(C)C1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMILES transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development\n",
    "I chose to develop a transformer-based model based on several desirable features:\n",
    "* SMILES is a widely used and convenient sequence-based representation for molecules.\n",
    "* Transformers are an established, scalable architecture for sequence-based models.\n",
    "* The molecules in the dataset are small enough such that a transformer attention mechanism should be possible to capture the multi-atom relationships that are responsible for biological actvity.\n",
    "* Extensive existing transformer-related codebases such as Hugging Face's `transformers` could be leveraged if necessary.\n",
    "\n",
    "This model was developed in pytorch without additional frameworks. Pytorch already has good support for transformers, and a pure pytorch implementation allowed for greater control over the architecture.\n",
    "\n",
    "#### Initial search\n",
    "The first [model architecture](src/transformer/model.py) tested used sinusoidal positional encoding and a transformer encoder architecture with a final linear layer for regression. A key consideration was how to introduce class conditioning information. Based on the ability of transformers to propagate information via self-attention, I chose to prepend special tokens representing measurement type and kinase type to the transformer input. This choice also allows classes to be specified during inference in the same manner for prediction across kinases.\n",
    "\n",
    "The MSE loss values are not directly comparable to later runs but are internally comparable (target values from different measurement types were normalized by measurement type in an effort to avoid different scales biasing training gradients, but this was later decided to be the wrong strategy as this destroys discriminative information). \n",
    "\n",
    "An initial model hyperparameter search was run over 50 iterations optimizing key parameters in the ranges below: \n",
    "* embedding size (`hidden_dim`): [256, 512, 768]\n",
    "* number of attention heads (`num_heads`): [4, 8, 16]\n",
    "* number of layers (`num_layers`): [6 - 12, integer]\n",
    "* dropout probability (`dropout`): [0.1 - 0.5, float]\n",
    "\n",
    "(mlflow experiment \"[Transformer Architecture Search](http://127.0.0.1:5000/#/experiments/429830334311556039?viewStateShareKey=60b5838b3c07b10d688fd52b4dd6c37593b139dcfb12d21877e12fcb552682f6)\")\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"figures/transformer_optuna_parallel.png\" alt=\"Transformer Optuna Parallel\">\n",
    "    <br>\n",
    "    <em>Parallel coordinates plot from hyperparameter search linking transformer parameters to validation loss.</em>\n",
    "</p>\n",
    "\n",
    "This plot indicates that embedding size and number of attention heads above a certain level are crucial. Both of these parameters are linked to model capacity, indicating that the expressiveness of tokens and links between them may not be saturated with this model architecture. Number of transformer layers was less important, indicating sufficient propagation of infomation.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"figures/transformer_optuna_loss.png\" alt=\"Transformer Optuna Loss\">\n",
    "    <br>\n",
    "    <em>Overlaid training loss curves from hyperparameter search. y-axis: MSE loss in log scale. x-axis: training epochs.</em>\n",
    "</p>\n",
    "\n",
    "The overlaid training curves show that under certain conditions, training does not converge or undergoes a long initial plateau period - direct inspection of these runs shows these arise primarily from high dropout rates above 0.2, as would be expected for excessive regularization.\n",
    "\n",
    "#### Updating architectural choices\n",
    "After updating the system to use unscaled target values, model performance was reappraised against the gradient boosting baseline model and found to be worse. The positional encoding architecture was considered as a point of potential improvement: the sinusoidal encoding chosen initially only encodes absolute positions. SMILES strings are degenerate to a given molecule, so relative positions might aid generalization. A relative positional encoder, RoPE, was then tested using the `torchtune` library implementation, [`RotaryPositionalEmbeddings`](https://pytorch.org/torchtune/0.3/generated/torchtune.modules.RotaryPositionalEmbeddings.html#torchtune.modules.RotaryPositionalEmbeddings). The initial test with this encoder showed training loss lower than any previous run, however validation loss did not improve significantly. This indicated the RoPE encoder was improving the model's ability to learn the training set, but this was not generalizing ([mlflow run](http://127.0.0.1:5000/#/experiments/431121963238412000/runs/ef6bf6825f5a4112bd93b05e2e2c7acb)).\n",
    "\n",
    "To provide regularization the model capacity was reduced, dropout increased, weight decay, and learning rate warmup/decay were implemented ([mlflow run](http://127.0.0.1:5000/#/experiments/431121963238412000/runs/372d334383784b0093884a09192964b7)). However, the learning curves showed the same overfitting pattern.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"figures/RoPE_regularization.png\" alt=\"RoPE Regularization\">\n",
    "    <br>\n",
    "    <em>Training and validation loss curves for the first RoPE model (green: training, red: validation) and for the model with regularizations (blue: training, orange: validation). y-axis: MSE loss in log scale. x-axis: training epochs.</em>\n",
    "</p>\n",
    "\n",
    "An additional form of regularization was introduced via SMILES string scrambling (as SMILES strings have multiple equivalent representations for a given molecule), which can also be considered a form of data augmentation. The aim of this was to prevent the model's ability to memorize specific SMILES strings, in order to improve generalization. The initial test reduced training set overfitting but did not change validation set results ([mlflow run](http://127.0.0.1:5000/#/experiments/431121963238412000/runs/d454fdfbd9bc4f30964d23c70986a30a)). Other forms of regularization were then reduced and model capacity increased again ([mlflow run](http://127.0.0.1:5000/#/experiments/431121963238412000/runs/40dd666bf60640ba950bb01f11f6e20c)); a comparison between the learning curves for this and the first RoPE model are shown below. \n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"figures/RoPE_SMILES_scrambling.png\" alt=\"RoPE SMILES Scrambling\">\n",
    "    <br>\n",
    "    <em>Training and validation loss curves for first RoPE model (green: training, red: validation) and for the high capacity scrambled SMILES model (blue: training, orange: validation). y-axis: MSE loss in log scale. x-axis: training epochs.</em>\n",
    "</p>\n",
    "\n",
    "Having made these changes, we see a reduction in training-set overfitting but no significant improvement in generalization ability on the validation set.\n",
    "\n",
    "Note: A mistake was made where the SMILES strings of the validation set were also dynamically scrambled. A run fixing this was performed ([mlflow run](http://127.0.0.1:5000/#/experiments/431121963238412000/runs/5ace52da25254652a3a9c358f84300fb)) but no major differences in validation loss were observed.\n",
    "\n",
    "#### Summary\n",
    "A SMILES transformer for class-based regression was developed. Several augmentations were tested: hyperparameter tuning in the transformer architecture, positional encoder variations, and SMILES string scrambling for regularization/data augmentation. Technical details are described in the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset setup\n",
    "[dataset.py](src/transformer/dataset.py)\n",
    "\n",
    "A torch `Dataset`, `SMILESDataset` is defined which ingests the provided data as a dataframe.\n",
    "\n",
    "The `__getitem__` returns the tokenized SMILES strings prepended with two special tokens representing measurement type and kinase name.\n",
    "\n",
    "The token vocabulary is pre-calculated from the dataframe and a list of special tokens using the `build_vocabulary` function in [utils.py](src/utils.py) and then passed as an initialization argument to `SMILESDataset`. For a production deployment, a vocab should be pre-calculated which works for all possible SMILES strings.\n",
    "\n",
    "The `create_stratified_splits` function is used to ensure class representation.\n",
    "\n",
    "Additional helper functions `collate_fn` and `create_loaders` are used to pad batches and create dataloaders, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup\n",
    "The model `TransformerModel` is based on transformer encoder architecture with a linear layer over the output logits to perform regression. Dropout layers are used to provide regularization.\n",
    "\n",
    "In [model.py](src/transformer/model.py), sinusoidal positional encoding is implemented via `PositionalEncoding`.\n",
    "\n",
    "In [model_rope.py](src/transformer/model_rope.py) a relative positional encoding `RotaryPositionalEmbeddings` is used from the `torchtune` library.\n",
    "\n",
    "The embedding size (`hidden_dim`), number of attention heads (`num_heads`), number of layers (`num_layers`), and dropout probability (`dropout`) are written as variables so that they can be optimized via hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setup\n",
    "[train_transformer.py](src/train_transformer.py)\n",
    "\n",
    "The function `train_one_epoch` defines a single training epoch. `validate` defines a validation epoch. An optional data scaling capability is implemented (and tested with min-max scaling) but was not used in later experiments.\n",
    "\n",
    "In a single training run:<br>\n",
    "* Tracking is set up using a local mlflow server.\n",
    "* Dataloaders are set up (see \"Dataset Setup\" for further details)\n",
    "* Transformer model parameters are specified\n",
    "* A loss criterion is defined. Mean squared error was chosen as a standard loss for regression problems.\n",
    "* An optimizer and learning rate are defined. The Adam optimizer with learning rate 1e-4 was chosen as a generally effective option.\n",
    "* Regularizations are selected: weight decay, learning rate scheduling, annealing strategy\n",
    "* A training loop is run by calling `train_one_epoch` and `validate` for a fixed number of epochs. Loss metrics are logged to mlflow for visualization and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "[hyperparameter_search_transformer.py](src/hyperparameter_search_transformer.py)\n",
    "\n",
    "Bayesian hyperparameter optimization was performed using the optuna framework.\n",
    "\n",
    "Key neural architecture parameters were optimized:\n",
    "* embedding size (`hidden_dim`)\n",
    "* number of attention heads (`num_heads`)\n",
    "* number of layers (`num_layers`)\n",
    "* dropout probability (`dropout`)\n",
    "\n",
    "Trials were also logged with mlflow to provide tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "Like the gradient boosting model, the transformer model has much better performance on ENZ1 compared to the other classes ([mlflow run](http://127.0.0.1:5000/#/experiments/181390553139269171/runs/193d252eb46e4ff69c1b614750ffdfc4)).\n",
    "\n",
    "enzyme_name | pKi MSE\n",
    "--- | ---\n",
    "ENZ1 | 0.122952\n",
    "ENZ2 | 0.450943\n",
    "ENZ3 | 0.591636\n",
    "ENZ4 | 0.811755\n",
    "Overall | 0.494321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "[app_transformer.py](src/app_transformer.py)\n",
    "\n",
    "A web service with a similar API to the one implemented for the gradient boosting model is demonstrated below. A different backend is used to preprocessthe input. The service is written in flask and runs a pytorch model pulled from the local mlflow server. The user sends the details of a molecule and the measurement conditions (SMILES string, measurement type (pKi or pIC50), and enzyme name.\n",
    "\n",
    "The service tokenizes the molecule and measurement conditions, runs the SMILES transformer model and returns a predicted value. (Again, the real value is 7.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[7.841602325439453]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of the Flask app\n",
    "url = 'http://localhost:5001/predict'\n",
    "\n",
    "# Define the input data\n",
    "data = {\n",
    "        \"SMILES\": \"C#CCNCC1CCC(c2nnn3cnc4[nH]ccc4c23)CC1\",\n",
    "        \"measurement_type\": \"pIC50\",\n",
    "        \"enzyme_name\": \"ENZ2\"\n",
    "    }\n",
    "\n",
    "# Send a POST request to the /predict endpoint\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Print the response from the server\n",
    "if response.status_code == 200:\n",
    "    print(\"Predictions:\", response.json())\n",
    "else:\n",
    "    print(\"Error:\", response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to a string based model, a graph-based model has several advantages:\n",
    "* A graph is a natural representation for molecules\n",
    "* Using a graph representation removes the problem of degenerate SMILES strings as the final graph embedding is SMILES-permutation invariant\n",
    "* Additional chemical information can, in principle, be encoded in both graph nodes and edges.\n",
    "* While less common than transformers, there are plenty of existing codebases designed for deep learning on graphs.\n",
    "\n",
    "I chose to develop this model in pytorch using the pytorch-geometric framework for computations on graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development\n",
    "The core architecture of stacked graph convolutional layers for learning molecules is very well established (in e.g. [Kipf & Welling 2017](https://arxiv.org/abs/1609.02907)). My main concern was how to introduce class conditioning information (measurement type and kinase name). An initial attempt was to append this information as a one-hot vector to each atom node's feature vector, but this did not work well and seemed inelegant. I then decided on the approach of embedding the class information into the graph model's hidden dimension and adding it after pooling: [model.py](src/gnn/model.py).\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"figures/gnn_training_dynamics.png\" alt=\"GNN Training Dynamics\">\n",
    "    <br>\n",
    "    <em> Exploratory training curves for the graph model with a range of hyperparameters. y-axis: MSE loss in log scale. x-axis: training epochs.</em>\n",
    "</p>\n",
    "\n",
    "The figure above shows the inital testing of model hyperparameters and how they affect the model training loss. The first experiment, represented by the brown trace (hidden dimension = 32, layers = 3) showed extremely slow convergence, so model hidden dimension was increased to 128. The other trials in this plot show different combinations of larger hidden dimension and more layers. All showed similar training dynamics - an initial rapid convergence period, followed by a loss plateau.\n",
    "\n",
    "To further optimize this model, several parameters were considered for hyperparameter search:\n",
    "* embedding size (`hidden_dim`): [256, 512, 768]\n",
    "* number of layers (`num_layers`): [3 - 10, integer]\n",
    "* convolutional layer type (`conv_type`): [GATConv, GCNConv, SAGEConv, GraphConv, TAGConv]\n",
    "* normalization layer type (`norm_type`): [None, LayerNorm, BatchNorm]\n",
    "* pooling layer type (`pool_type`): [global_mean_pool, global_max_pool, global_add_pool]\n",
    "\n",
    "A selection of convolutional layer types with different designs were tested: GATConv, GCNConv, SAGEConv, GraphConv, TAGConv. These were chosen from pytorch geometric's library of convolution layers, based on differences in terms of how they aggregate information - e.g. GATConv uses graph attention, while TAGConv learns graph topology. Normalization layers were tested to see if they improved training dynamics. Three common pooling layers were tested to see if they improved the model's ability to generalize by providing different ways of aggregating node information. The hyperparameter search results are tracked in this [mlflow experiment](http://127.0.0.1:5000/#/experiments/429055189571193624?viewStateShareKey=381a0e300ab95848b02f3396ae0b80929e2073078e09976563757138a9db2a9b).\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"figures/gnn_parallel.png\" alt=\"GNN Hyperparameter Search\">\n",
    "    <br>\n",
    "    <em>Parallel coordinates plot from hyperparameter search linking GNN parameters to validation loss. The labels to categorical features could not be rendered correctly but are described below.</em>\n",
    "</p>\n",
    "\n",
    "The following parameters were found to perform well:\n",
    "* embedding size: 768 (as this was the largest option, higher dimensionalities may work even better)\n",
    "* number of layers: 5 (4-6 seemed to work best)\n",
    "* convolutional layer type: TAGConv (topology adaptive graph convolution)\n",
    "* normalization layer type: BatchNorm\n",
    "* pooling layer type: global_mean_pool (global_add_pool performed significantly worse)\n",
    "\n",
    "In terms of validation loss, the best GNN models performed similarly to the best transformer models.\n",
    "\n",
    "Technical details are described in the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset setup\n",
    "[dataset.py](src/gnn/dataset.py)\n",
    "\n",
    "A torch `Dataset`, `GraphDataset` is defined which ingests the provided data as a dataframe.\n",
    "\n",
    "The `__getitem__` uses rdkit to convert the SMILES string into a rdkit mol. Atomic features are added to the nodes (atoms) via a one-hot encoding of element type. The method returns a pytorch geometric data item along containing node and edge information. A one-hot encoding of categorical features is added as the `cat_features` attribute to be used for conditioning.\n",
    "\n",
    "A `create_loaders` helper function is defined that uses pytorch geometric's GeometricDataLoader designed for graph data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup\n",
    "[model.py](src/gnn/model.py)\n",
    "\n",
    "The model `GraphModel` is based on a graph convolutional architecture with a linear layer over the output logits to perform regression. In order to condition the model on measurement type and kinase name, the one-hot categorical feature vector calculated in the `GraphDataset` is embedded into the model hidden dimension through a linear layer and added to the pooled graph embedding.\n",
    "\n",
    "The embedding size (`hidden_dim`), convolutional layer type (`conv_type`), number of layers (`num_layers`), presence and type of normalization layers (`norm_type`) and dropout probability (`dropout`) are left as variables which can be optimized via hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setup\n",
    "[train_gnn.py](src/train_gnn.py)\n",
    "\n",
    "The GNN training script is very similar to the transformer script, except for data preprocessing and model setup. \n",
    "\n",
    "The function `train_one_epoch` defines a single training epoch. `validate` defines a validation epoch.\n",
    "\n",
    "In a single training run:<br>\n",
    "* Tracking is set up using a local mlflow server.\n",
    "* Dataloaders are set up (see \"Dataset Setup\" for further details)\n",
    "* Graph model parameters are specified\n",
    "* A loss criterion is defined.\n",
    "* An optimizer and learning rate are defined.\n",
    "* A training loop is run by calling `train_one_epoch` and `validate` for a fixed number of epochs. Loss metrics are logged to mlflow for visualization and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "[hyperparameter_search_gnn.py](src/hyperparameter_search_gnn.py)\n",
    "\n",
    "Bayesian hyperparameter optimization was performed using the optuna framework.\n",
    "\n",
    "Key neural architecture parameters were optimized:\n",
    "* embedding size (`hidden_dim`): [256, 512, 768]\n",
    "* number of layers (`num_layers`): [3 - 10, integer]\n",
    "* convolutional layer type (`conv_type`): [GATConv, GCNConv, SAGEConv, GraphConv, TAGConv]\n",
    "* normalization layer type (`norm_type`): [None, LayerNorm, BatchNorm]\n",
    "* pooling layer type (`pool_type`): [global_mean_pool, global_max_pool, global_add_pool]\n",
    "\n",
    "Trials were also logged with mlflow to provide tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "Compared to the transformer model, the GNN model improved on ENZ4 while being worse on ENZ1, leading to a similar overall test loss ([mlflow run](http://127.0.0.1:5000/#/experiments/559023913998728002/runs/c1898b63ffad4ac69d23e10e86346570)). Further research may show if the two models differ in their capacity to represent specific chemical concepts.\n",
    "\n",
    "Kinase_name | pKi MSE\n",
    "--- | ---\n",
    "ENZ1 | 0.229687\n",
    "ENZ2 | 0.635797\n",
    "ENZ3 | 0.521044\n",
    "ENZ4 | 0.587860\n",
    "Overall | 0.493597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final discussion\n",
    "A comparison of model evaluation metrics on the held-out test set of 60 pKi samples from each kinase class is shown in the table below. Further work such as a statistical comparison of cross-validation scores would clarify the significance of comparing scores between classes but we can see that all models gave MSE test losses of below 0.5, corresponding to a pKi difference of less than 1. \n",
    "\n",
    "\n",
    "This would be sufficient to identify lead molecules with high selectivity for further investigation.\n",
    "\n",
    "Kinase_name |  Gradient Boosting (pKi MSE) | Transformer (pKi MSE) | GNN (pKi MSE)\n",
    "--- | --- | --- | ---\n",
    "ENZ1 | 0.096965 | 0.122952 | 0.229687\n",
    "ENZ2 | 0.262585 | 0.450943 | 0.635797\n",
    "ENZ3 | 0.366490 | 0.591636 | 0.521044\n",
    "ENZ4 | 0.334674 | 0.811755 | 0.587860\n",
    "Overall | 0.265178 | 0.494321 | 0.493597\n",
    "\n",
    "The gradient boosting regressor seemingly outperforms both the deep learning models. The handcrafted molecular featurization routines found in rdkit and other packages may provide additional domain knowledge beyond the pure SMILES string. Both deep learning models reached a similar level of performance slightly below that of the gradient boosting model, suggesting they may be nearing the maximum predictive ability of a pure SMILES representation.\n",
    "\n",
    "This suggests that adding handcrafted features to a deep learning model might improve performance, particularly for small datasets. For example, a feature-importance ranking method such SHAP could be used on the gradient boosting model to select the most useful features. To implement a hybrid deep learning model, features could be introduced as special tokens in the transformer model, or by concatenation to the categorical features in the GNN model. Another clear possibility for GNN model improvement is to add more node and edge features to the molecular graphe.g. atomic properties such as electronegativity, or bond features such as bond order.\n",
    "\n",
    "An alternative direction that would likely have clear performance benefits is pre-training the deep learning models on a large chemical corpus before finetuning on tasks like this kinase challenge. The pre-trained models could also be repurposed for other applications. Alternatively, existing pre-trained models could be used as base models.\n",
    "\n",
    "Interpretability would also be an interesting research direction, possibly leading to deeper chemical understanding of the inhibition mechanisms. As mentioned above, simple feature importance rankings can be useful for traditional ML models. For the transformer model, visualization of attention head activation may provide clues as to which chemical components are linked to kinase inhibition activity. For the GNN, an analogous study could be done visualizing the graph convolutions. This could lead to the identification of new pharmacophores.\n",
    "\n",
    "Example deployments were shown of two of the models as web services. In production, these deployments would need to be built out in several ways. The services would need to be containerized and run on cloud servers. Models could be continually be trained with new data using automated pipelines and orchestrated by a mlflow server or other similar service. Many aspects of the API would need to be made more robust and secure. Two potential uses of such a service would be for direct consumption by research chemists, and for usage in automated computational pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
